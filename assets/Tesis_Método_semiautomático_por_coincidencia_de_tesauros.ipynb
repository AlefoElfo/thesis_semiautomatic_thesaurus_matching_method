{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VXf0X8ePFn5"
      },
      "source": [
        "# Librería"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrazTXV7QGJz",
        "outputId": "8ba32453-9c66-4210-fa0c-bf30f8cfa379"
      },
      "outputs": [],
      "source": [
        "# INSTALACIÓN DE LIBRERÍAS\n",
        "\n",
        "# Evitar problemas en Google Colab con spaCy\n",
        "!pip install -U blis\n",
        "# Instalando spaCy en Google Colab\n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "# Usar modelo largo en español\n",
        "!python -m spacy download es_core_news_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sKsGzaf0GGf9"
      },
      "outputs": [],
      "source": [
        "# Llamar a librerías\n",
        "import json\n",
        "import spacy\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BX04oQQPFrq"
      },
      "source": [
        "# Tesauro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HUkYX8d5Pw5O"
      },
      "outputs": [],
      "source": [
        "def tesauro(url):\n",
        "  global statenLista\n",
        "  # [1] JSON EN PYTHON\n",
        "  # with open(url, encoding='utf-8') as statenFile:\n",
        "  #     staten = json.load(statenFile)\n",
        "  staten = json.loads(requests.get(url).text)\n",
        "  print(f'''--------------\n",
        "[1] \n",
        "Archivo JSON ingresado como DICT\n",
        "Con {len(staten)} atributos:\n",
        "''')\n",
        "  for key,value in staten.items():\n",
        "      print(key)\n",
        "      statenValue = str(value)\n",
        "\n",
        "  # [2] LIMPIAR STRING\n",
        "  residuosJSON = '''[]{}\"\"':,'''\n",
        "  replace = ''\n",
        "  for value in statenValue:\n",
        "      if value in residuosJSON:\n",
        "          statenValue = statenValue.replace(value, '')\n",
        "  statenLower = statenValue.lower()\n",
        "  print('''--------------\n",
        "\n",
        "[2]\n",
        "Archivo DICT se ha limpiado\n",
        "--------------''')\n",
        "\n",
        "  # [3] SPACY\n",
        "  nlp = spacy.load('es_core_news_md')\n",
        "  statenNLP = (set(nlp(statenLower)))\n",
        "  statenLista = []\n",
        "  for token in statenNLP:\n",
        "      if not token.is_stop:\n",
        "          if not token.is_punct: #¿Qué es más eficiente para el procesador?\n",
        "              statenLista.append(token.lemma_)\n",
        "  print(f'''\n",
        "[3]\n",
        "Archivo DICT leído con PLN. {len(statenLista)} campos de búsqueda\n",
        "--------------''')\n",
        "\n",
        "  return statenLista"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef-ASXFLPF01"
      },
      "source": [
        "# Pregunta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cvWI1sfTTmup"
      },
      "outputs": [],
      "source": [
        "def pregunta():\n",
        "  global preguntaLista\n",
        "  # [1] Hacer input de pregunta natural\n",
        "  nlp = spacy.load('es_core_news_md')\n",
        "  pregunta = (input('''\n",
        "[4]\n",
        "Si no recuerdas el término, pregúntame, o trata de escribir lo que recuerdes:\n",
        "(Nota: El diccionario cuenta con 70 términos. Trabajamos para que crezca)\n",
        "ESCRIBE TU PREGUNTA ↓\n",
        "→ '''))\n",
        "  preguntaLower = nlp(pregunta.lower())\n",
        "  preguntaLista = []\n",
        "  for token in preguntaLower:\n",
        "      if not token.is_stop:\n",
        "          if not token.is_punct:\n",
        "              preguntaLista.append(token.lemma_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkOvtfsIPF3h"
      },
      "source": [
        "# Coincidencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7WdX_EEWUDOw"
      },
      "outputs": [],
      "source": [
        "def coincidencias():\n",
        "  # [1] Buscar coincidencias en lista de términos con lista de pregunta\n",
        "  global statenLista\n",
        "  global preguntaLista\n",
        "  global coincidenciasSet\n",
        "  coincidencias = []\n",
        "  for eS in statenLista:\n",
        "      for eP in preguntaLista:\n",
        "          if set(eS) == set(eP):\n",
        "              coincidencias.append(eS)\n",
        "              coincidenciasSet = set(coincidencias)\n",
        "  print(f'''--------------\n",
        "\n",
        "[5]\n",
        "Hemos encontrado {len(coincidenciasSet)} coincidencias:\n",
        "{coincidenciasSet}''')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECbw1C5FPF6t"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dj3EwD_TWLLe"
      },
      "outputs": [],
      "source": [
        "def metodotesauro(archivojson):\n",
        "  print('Método semi automático por concidencia de tesauro')\n",
        "  tesauro(archivojson)\n",
        "  pregunta()\n",
        "  coincidencias()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glQgjO2ed53m"
      },
      "source": [
        "## Statenvertaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g82kIlYUXCVr",
        "outputId": "1bfb6721-16e5-4b9f-c6e6-97d2b4bfff81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Método semi automático por concidencia de tesauro\n",
            "--------------\n",
            "[1] \n",
            "Archivo JSON ingresado como DICT\n",
            "Con 9 atributos:\n",
            "\n",
            "Nombre\n",
            "Sinónimos\n",
            "Hiperónimos\n",
            "Cohipónimos\n",
            "Hipónimos\n",
            "Polisemia\n",
            "Antonimia\n",
            "Meronimia\n",
            "Definición\n",
            "--------------\n",
            "\n",
            "[2]\n",
            "Archivo DICT se ha limpiado\n",
            "--------------\n",
            "\n",
            "[3]\n",
            "Archivo DICT leído con PLN. 72 campos de búsqueda\n",
            "--------------\n",
            "--------------\n",
            "\n",
            "[5]\n",
            "Hemos encontrado 4 coincidencias:\n",
            "{'país', 'bajo', 'biblia', 'traducción'}\n"
          ]
        }
      ],
      "source": [
        "# URL con JSON de \"Statenvertaling\"\n",
        "url = 'https://raw.githubusercontent.com/AlefoElfo/thesis_semiautomatic_thesaurus_matching_method/main/assets/Statenvertaling.json'\n",
        "metodotesauro(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skfekJYLbM03"
      },
      "source": [
        "## Biblia del Oso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YYEMA89d_UE",
        "outputId": "a1f59a7d-18ab-4344-8ebd-f188388f64f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Método semi automático por concidencia de tesauro\n",
            "--------------\n",
            "[1] \n",
            "Archivo JSON ingresado como DICT\n",
            "Con 9 atributos:\n",
            "\n",
            "Nombre\n",
            "Sinónimos\n",
            "Hiperónimos\n",
            "Cohipónimos\n",
            "Hipónimos\n",
            "Polisemia\n",
            "Antonimia\n",
            "Meronimia\n",
            "Definición\n",
            "--------------\n",
            "\n",
            "[2]\n",
            "Archivo DICT se ha limpiado\n",
            "--------------\n",
            "\n",
            "[3]\n",
            "Archivo DICT leído con PLN. 59 campos de búsqueda\n",
            "--------------\n",
            "--------------\n",
            "\n",
            "[5]\n",
            "Hemos encontrado 3 coincidencias:\n",
            "{'país', 'biblia', 'traducción'}\n"
          ]
        }
      ],
      "source": [
        "# Biblia del oso\n",
        "url = 'https://raw.githubusercontent.com/AlefoElfo/thesis_semiautomatic_thesaurus_matching_method/main/assets/BibliaOso.json'\n",
        "metodotesauro(url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "f363b6552389bb5843ae6ef674413dc477fa310722bf5be5fb5c6d7e5809c86d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
